include required(classpath("application"))

system {
    job-rate-control {
        jobs = 1
            per = 1 second
    }
}

workflow-options {
    workflow-failure-mode: "ContinueWhilePossible"
}

database {
    # profile = "slick.jdbc.HsqldbProfile$"
    #     db {
    #         driver = "org.hsqldb.jdbcDriver"
    #             url = """
    #             jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;
    #         shutdown=false;
    #         hsqldb.default_table_type=cached;hsqldb.tx=mvcc;
    #         hsqldb.result_max_memory_rows=10000;
    #         hsqldb.large_data=true;
    #         hsqldb.applog=0;
    #         hsqldb.lob_compressed=true;
    #         hsqldb.script_format=3
    #             """
    #             connectionTimeout = 120000
    #             numThreads = 2
    #     }
}

call-caching {
    enabled = false
        invalidate-bad-cache-results = false
}

backend {
    default = "Slurm"
        providers {
            Slurm {
                actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
                    config {
                        concurrent-job-limit = 10
# If an 'exit-code-timeout-seconds' value is specified:
#     - check-alive will be run at this interval for every job
#     - if a job is found to be not alive, and no RC file appears after this interval
#     - Then it will be marked as Failed.
## Warning: If set, Cromwell will run 'check-alive' for every job at this interval
                            # exit-code-timeout-seconds = 360 
                            filesystems {
                                local {
                                    localization: [
# soft link does not work for docker with --contain. Hard links won't work
# across file systems
                                        "hard-link", "cached-copy", "copy"
                                        ]
                                }
                            }
                        default-runtime-attributes {
                            maxRetries = 0
                        }

                        runtime-attributes = """
                            Int hpcRuntimeMinutes
                            Int cpu
                            Int hpcMemory
                            String hpcQueue
                            Int? gpuCount
                            String? gpuType
                            """
                        ## TODO: submit with hyperthreading disabled
                        submit = """
                            sbatch \
                            -J ${job_name} \
                            -D ${cwd} \
                            -o ${out} \
                            -e ${err} \
                            -t ${hpcRuntimeMinutes} \
                            -c ${cpu} \
                            --mem ${hpcMemory}g \
                            --partition ${hpcQueue} \
                            ${if defined(gpuCount) then 
                                (if defined(gpuType) then ('--gres=gpu:' + gpuType + ':' + gpuCount)
                                else ('--gres=gpu:' + gpuCount))
                                    else ''} \
                                        --wrap "/bin/bash ${script}"
                            """

                        kill = "scancel ${job_id}"
                        check-alive = "dashboard_cli jobs --is-active -j ${job_id}"
                        job-id-regex = "(\\d+)"
            }
        }
}
}
